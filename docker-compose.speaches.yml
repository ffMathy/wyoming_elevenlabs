services:
  wyoming_openai:
    image: ghcr.io/roryeckel/wyoming_openai:latest
    container_name: wyoming_openai
    ports:
      - "10300:10300"
    restart: unless-stopped
    environment:
      WYOMING_URI: tcp://0.0.0.0:10300
      WYOMING_LOG_LEVEL: INFO
      WYOMING_LANGUAGES: en
      STT_OPENAI_URL: http://speaches:8000/v1
      STT_MODELS: "Systran/faster-distil-whisper-large-v3"
      STT_BACKEND: "SPEACHES"
      TTS_OPENAI_URL: http://speaches:8000/v1
      TTS_MODELS: "hexgrad/Kokoro-82M"
      TTS_BACKEND: "SPEACHES"
      # TTS_VOICES: "af af_bella af_sarah am_adam am_michael bf_emma bf_isabella bm_george bm_lewis af_nicole af_sky"
    depends_on:
      speaches:
        condition: service_healthy

  # https://speaches.ai/usage/text-to-speech/#prerequisite
  # init-speaches:
  #   image: ghcr.io/speaches-ai/speaches:latest-cuda
  #   container_name: init-models
  #   environment:
  #     - KOKORO_REVISION=c97b7bbc3e60f447383c79b2f94fee861ff156ac
  #   command: >
  #     /bin/bash -c '
  #       export REVISION=$${KOKORO_REVISION} &&
  #       huggingface-cli download hexgrad/Kokoro-82M --include "kokoro-v0_19.onnx" --revision $${REVISION} &&
  #       curl --location --output /home/ubuntu/.cache/huggingface/hub/models--hexgrad--Kokoro-82M/snapshots/$${REVISION}/voices.bin https://github.com/thewh1teagle/kokoro-onnx/releases/download/model-files/voices.bin
  #     '
  #   volumes:
  #     - huggingface-hub:/home/ubuntu/.cache/huggingface/hub
  #   runtime: nvidia
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             capabilities: [ gpu ]

  speaches:
    container_name: speaches
    image: ghcr.io/speaches-ai/speaches:latest-cuda
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      - enable_ui=False
      - log_level=info
      - WHISPER__MODEL=Systran/faster-distil-whisper-large-v3
      - WHISPER__compute_type=int8_float32
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    volumes:
      - huggingface-hub:/home/ubuntu/.cache/huggingface/hub
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [ gpu ]
    runtime: nvidia
    # depends_on:
    #   init-speaches:
    #     condition: service_completed_successfully

volumes:
  huggingface-hub: